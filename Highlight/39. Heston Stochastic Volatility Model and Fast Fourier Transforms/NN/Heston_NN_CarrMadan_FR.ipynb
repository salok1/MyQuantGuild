{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b96c968",
   "metadata": {},
   "source": [
    "\n",
    "# Calibration de Heston via Reseau de Neurones + Couche de Pricing Carr-Madan (PyTorch)\n",
    "\n",
    "Notebook didactique en francais.  \n",
    "Objectif: predire les parametres du modele de Heston `(kappa, theta, sigma, rho, v0)` a partir de donnees marche `[r, T, S0, K, iv_BS]`, puis pricer un call avec une **couche de pricing differentiable** (Carr-Madan FFT) et apprendre par **descente de gradient** contre les **prix marche**.\n",
    "\n",
    "## Contenu\n",
    "1. Utilitaires Black-Scholes (prix et Vega) pour la perte ponderee.  \n",
    "2. Couche de pricing Heston differenciable (Carr-Madan) en `torch`.  \n",
    "3. reseau de neurones qui sort des parametres Heston avec contraintes de domaine.  \n",
    "4. Fonctions de perte: MSE ponderee par **Vega** + penalite **Feller**.  \n",
    "5. Jeu de donnees synthetique et boucle d'apprentissage.  \n",
    "6. Diagnostics rapides.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "56302e37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T21:48:22.843902Z",
     "start_time": "2025-11-11T21:48:22.837701Z"
    }
   },
   "source": [
    "\n",
    "# ==== Environnement ====\n",
    "# pip install torch --upgrade\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Precision numerique: float64 pour stabiliser l'FFT et l'autograd\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# Appareil de calcul\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "4f81a5bc",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Utilitaires Black-Scholes\n",
    "\n",
    "Ces fonctions servent a:\n",
    "- Generer des **prix cibles** synthetiques (si besoin).\n",
    "- Calculer la **Vega** pour **pondérer la MSE**.  \n",
    "  L'idee: la variance des erreurs n'est pas homogene sur la surface; ponderer par `1/vega` stabilise le signal d'apprentissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac266904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T21:48:22.893831Z",
     "start_time": "2025-11-11T21:48:22.889658Z"
    }
   },
   "source": [
    "\n",
    "# ---------------- Utilitaires Black-Scholes ----------------\n",
    "\n",
    "def _ncdf(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Fonction de repartition de la loi normale standard (vectorisee).\"\"\"\n",
    "    return 0.5*(1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "def bs_call(S0: torch.Tensor, K: torch.Tensor, T: torch.Tensor,\n",
    "            r: torch.Tensor, q: torch.Tensor, vol: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Prix du call European sous Black-Scholes (vectorise).\n",
    "    Sert pour fabriquer des cibles synthetiques ou des bases de comparaison.\n",
    "    \"\"\"\n",
    "    eps = torch.tensor(1e-12, dtype=S0.dtype, device=S0.device)\n",
    "    S0, K, T, r, q, vol = map(lambda t: t.to(S0.dtype), (S0, K, T, r, q, vol))\n",
    "    d1 = (torch.log(S0/K) + (r - q + 0.5*vol*vol)*T) / (vol*torch.sqrt(T+eps) + eps)\n",
    "    d2 = d1 - vol*torch.sqrt(T+eps)\n",
    "    return S0*torch.exp(-q*T)*_ncdf(d1) - K*torch.exp(-r*T)*_ncdf(d2)\n",
    "\n",
    "def bs_vega(S0: torch.Tensor, K: torch.Tensor, T: torch.Tensor,\n",
    "            r: torch.Tensor, q: torch.Tensor, vol: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Vega = dC/dvol sous Black-Scholes.\n",
    "    Utilisee comme poids de la perte: w = 1/(Vega + eps).\n",
    "    \"\"\"\n",
    "    eps = torch.tensor(1e-12, dtype=S0.dtype, device=S0.device)\n",
    "    d1 = (torch.log(S0/K) + (r - q + 0.5*vol*vol)*T) / (vol*torch.sqrt(T+eps) + eps)\n",
    "    phi = torch.exp(-0.5*d1*d1) / math.sqrt(2.0*math.pi)  # densite normale\n",
    "    return S0*torch.exp(-q*T)*phi*torch.sqrt(T+eps)\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "bd64ff1e",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Couche de pricing Heston (Carr-Madan FFT)\n",
    "\n",
    "### Idees cles\n",
    "- On utilise la **transformee de Fourier** du call amorti par `alpha` (Carr-Madan).  \n",
    "- On evalue la **fonction caracteristique** (CF) de Heston avec le **Little Heston Trap** pour la stabilite numerique (`|g| < 1`).  \n",
    "- On integre numeriquement via une **grille de frequences** et des **poids de Simpson**, puis **FFT**.  \n",
    "- Interpolation **lineaire en log-strike** `k = ln K`.\n",
    "\n",
    "La classe suivante est **differenciable** (PyTorch autograd) et vectorisee sur le batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "232d6fc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T21:48:22.982290Z",
     "start_time": "2025-11-11T21:48:22.975958Z"
    }
   },
   "source": [
    "\n",
    "# =========================\n",
    "# Heston + Carr-Madan (torch)\n",
    "# =========================\n",
    "\n",
    "class HestonPricingLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Couche de pricing differentiable.\n",
    "    Entrees: tenseurs batch (B,) pour S0,K,T,r,q et (kappa,theta,sigma,rho,v0).\n",
    "    Sortie: prix de call (B,).\n",
    "    \"\"\"\n",
    "    def __init__(self, N: int = 4096, eta: float = 0.25, alpha: float = 1.5):\n",
    "        super().__init__()\n",
    "        if N % 2 != 0:\n",
    "            raise ValueError(\"N doit etre pair (poids de Simpson).\")\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"alpha doit etre > 0 (amortissement).\")\n",
    "        self.N = N\n",
    "        self.eta = eta\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Grille des frequences v_n = n * eta et poids de Simpson\n",
    "        n = torch.arange(N, dtype=torch.float64)\n",
    "        v = eta * n\n",
    "        w = torch.ones(N, dtype=torch.float64)\n",
    "        w[1:N-1:2] = 4.0\n",
    "        w[2:N-2:2] = 2.0\n",
    "        w = w * (eta / 3.0)\n",
    "\n",
    "        # Buffers (deplaces automatiquement sur le bon device)\n",
    "        self.register_buffer(\"v\", v)\n",
    "        self.register_buffer(\"w\", w)\n",
    "\n",
    "        # Couplage FFT: pas en log-strike dk et demi-largeur b\n",
    "        dk = 2.0 * torch.pi / (N * eta)\n",
    "        b  = 0.5 * N * dk\n",
    "        # Stocke des scalaires; on les reconvertira en tenseurs dans forward\n",
    "        self.dk = float(dk.item())\n",
    "        self.b  = float(b.item())\n",
    "\n",
    "    def _heston_cf(self, u: torch.Tensor, T: torch.Tensor, S0: torch.Tensor,\n",
    "                   r: torch.Tensor, q: torch.Tensor,\n",
    "                   kappa: torch.Tensor, theta: torch.Tensor,\n",
    "                   sigma: torch.Tensor, rho: torch.Tensor, v0: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Fonction caracteristique de ln(S_T) sous Q (Little Heston Trap).\n",
    "        u: (B,N) complexe ; T,S0,r,q,kappa,theta,sigma,rho,v0: broadcastables a (B,1).\n",
    "        Retour: (B,N) complexe.\n",
    "        \"\"\"\n",
    "        i = torch.complex(torch.tensor(0., dtype=torch.float64, device=u.device),\n",
    "                          torch.tensor(1., dtype=torch.float64, device=u.device))\n",
    "        x0 = torch.log(S0)\n",
    "\n",
    "        a = kappa * theta\n",
    "        b = kappa - rho * sigma * i * u\n",
    "        d = torch.sqrt(b*b + (sigma**2) * (u*u + i*u))\n",
    "\n",
    "        g = (b - d) / (b + d)\n",
    "        # Stabilisation: force |g| < 1 numeriquement\n",
    "        mask = (g.abs() >= 1.0)\n",
    "        g = torch.where(mask, 1.0 / g, g)\n",
    "\n",
    "        eDT = torch.exp(-d * T)\n",
    "        one_minus_g = 1.0 - g\n",
    "        one_minus_g_eDT = 1.0 - g * eDT\n",
    "\n",
    "        eps = torch.tensor(1e-15, dtype=torch.float64, device=u.device)\n",
    "        one_minus_g = torch.where(one_minus_g.abs() < eps, eps, one_minus_g)\n",
    "        one_minus_g_eDT = torch.where(one_minus_g_eDT.abs() < eps, eps, one_minus_g_eDT)\n",
    "\n",
    "        C = i*u*(r - q)*T + (a/(sigma**2)) * ((b - d)*T - 2.0*torch.log(one_minus_g_eDT/one_minus_g))\n",
    "        D = ((b - d)/(sigma**2)) * ((1.0 - eDT)/one_minus_g_eDT)\n",
    "\n",
    "        return torch.exp(C + D*v0 + i*u*x0)\n",
    "\n",
    "    def forward(self, S0, K, T, r, q, kappa, theta, sigma, rho, v0) -> torch.Tensor:\n",
    "        \"\"\"Calcule le prix du call pour chaque ligne du batch.\"\"\"\n",
    "        device = S0.device\n",
    "        dtype  = torch.float64\n",
    "\n",
    "        v = self.v.to(device=device)\n",
    "        w = self.w.to(device=device)\n",
    "        N = self.N\n",
    "        alpha = torch.as_tensor(self.alpha, dtype=dtype, device=device)\n",
    "\n",
    "        # u = v - i*(alpha+1)\n",
    "        i = torch.complex(torch.tensor(0., dtype=dtype, device=device),\n",
    "                          torch.tensor(1., dtype=dtype, device=device))\n",
    "        u_shift = v - (alpha + 1.0)*i  # (N,) complexe\n",
    "\n",
    "        B = S0.shape[0]\n",
    "        u = u_shift.unsqueeze(0).expand(B, N)  # (B,N)\n",
    "\n",
    "        # Cast\n",
    "        S0 = S0.to(dtype); K = K.to(dtype); T = T.to(dtype)\n",
    "        r  = r.to(dtype);  q = q.to(dtype)\n",
    "        kappa = kappa.to(dtype); theta = theta.to(dtype)\n",
    "        sigma = sigma.to(dtype); rho = rho.to(dtype); v0 = v0.to(dtype)\n",
    "\n",
    "        # CF decalee\n",
    "        phi_shift = self._heston_cf(u, T[:,None], S0[:,None], r[:,None], q[:,None],\n",
    "                                    kappa[:,None], theta[:,None], sigma[:,None],\n",
    "                                    rho[:,None], v0[:,None])  # (B,N)\n",
    "\n",
    "        # Denominateur (alpha+iv)(alpha+iv+1)\n",
    "        denom = (alpha**2 + alpha - v**2 + (2*alpha + 1.0)*i*v)\n",
    "        denom = torch.where(denom.abs() < 1e-30,\n",
    "                            torch.complex(torch.tensor(1e-30, dtype=dtype, device=device),\n",
    "                                          torch.tensor(0., dtype=dtype, device=device)),\n",
    "                            denom)\n",
    "\n",
    "        psi = torch.exp(-r[:,None]*T[:,None]) * phi_shift / denom\n",
    "\n",
    "        # Couplage FFT\n",
    "        dk = torch.as_tensor(self.dk, dtype=dtype, device=device)\n",
    "        b  = torch.as_tensor(self.b,  dtype=dtype, device=device)\n",
    "        x  = psi * torch.exp(1j * b * v) * w  # (B,N)\n",
    "\n",
    "        F = torch.fft.fft(x, dim=-1).real  # (B,N)\n",
    "\n",
    "        j = torch.arange(N, dtype=dtype, device=device)\n",
    "        k_grid = -b + j * dk\n",
    "        calls_grid = torch.exp(-alpha * k_grid)[None, :] / torch.pi * F  # (B,N)\n",
    "\n",
    "        # Interpolation lineaire en log-strike\n",
    "        k_target = torch.log(K).to(dtype)\n",
    "        pos = (k_target + b) / dk\n",
    "        idx1 = torch.clamp(pos.floor().long(), 0, N-2)\n",
    "        idx2 = idx1 + 1\n",
    "\n",
    "        k0 = k_grid[idx1]\n",
    "        k1 = k_grid[idx2]\n",
    "        c0 = calls_grid.gather(1, idx1.view(-1,1)).squeeze(1)\n",
    "        c1 = calls_grid.gather(1, idx2.view(-1,1)).squeeze(1)\n",
    "        w1 = (k_target - k0) / (k1 - k0 + 1e-16)\n",
    "        price = c0 + (c1 - c0) * w1\n",
    "        return price\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "08772b06",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Reseau de neurones pour parametres Heston\n",
    "\n",
    "- Entree: `[r, T, S0, K, iv_BS]` pour chaque quote.  \n",
    "- Sortie: `kappa, theta, sigma, rho, v0` contraints au bon domaine  \n",
    "  (`softplus` pour positifs, `tanh` pour `rho`).  \n",
    "- `q` est fixe a 0 ici pour simplifier (on peut l'apprendre si besoin).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "24765e52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T21:48:23.123241Z",
     "start_time": "2025-11-11T21:48:23.119394Z"
    }
   },
   "source": [
    "\n",
    "class HestonCalibrator(nn.Module):\n",
    "    \"\"\"NN -> params Heston -> couche de pricing -> prix call.\"\"\"\n",
    "    def __init__(self, hidden: int = 128, N: int = 4096, eta: float = 0.25, alpha: float = 1.5):\n",
    "        super().__init__()\n",
    "        self.feature_net = nn.Sequential(\n",
    "            nn.Linear(5, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 6)  # kappa, theta, sigma, rho, v0, q_shift (optionnel)\n",
    "        )\n",
    "        self.pricer = HestonPricingLayer(N=N, eta=eta, alpha=alpha)\n",
    "\n",
    "        # Initialisation Xavier + biais de sortie plausibles\n",
    "        for m in self.feature_net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        with torch.no_grad():\n",
    "            self.feature_net[-1].bias[:] = torch.tensor([ 0.7,   # kappa ~ 1+\n",
    "                                                          -3.2,  # theta ~ 0.04\n",
    "                                                          -0.7,  # sigma ~ 0.33\n",
    "                                                           0.0,  # rho ~ 0\n",
    "                                                          -3.2,  # v0   ~ 0.04\n",
    "                                                           0.0], dtype=torch.float64)\n",
    "    def forward(self, x: torch.Tensor, C_mkt: torch.Tensor = None,\n",
    "                lambda_feller: float = 1e-3, lambda_ridge: float = 1e-6):\n",
    "        \"\"\"\n",
    "        x: (B,5) = [r, T, S0, K, iv_BS]\n",
    "        C_mkt: (B,) prix marche si fourni; sinon la fonction renvoie juste params + C_pred\n",
    "        Renvoie un dict contenant params, C_pred et (si C_mkt) la loss totale.\n",
    "        \"\"\"\n",
    "        dev = next(self.parameters()).device\n",
    "        x = x.to(dtype=torch.float64, device=dev)\n",
    "\n",
    "        r, T, S0, K, iv = x.unbind(dim=1)\n",
    "        raw = self.feature_net(x)\n",
    "        raw_kappa, raw_theta, raw_sigma, raw_rho, raw_v0, raw_qshift = raw.unbind(dim=1)\n",
    "\n",
    "        # Contraintes de domaine\n",
    "        kappa = F.softplus(raw_kappa) + 1e-6\n",
    "        theta = F.softplus(raw_theta) + 1e-8\n",
    "        sigma = F.softplus(raw_sigma) + 1e-8\n",
    "        rho   = 0.999 * torch.tanh(raw_rho)\n",
    "        v0    = F.softplus(raw_v0) + 1e-10\n",
    "        q     = torch.zeros_like(r)  # dividende fixe ici\n",
    "\n",
    "        # Pricing Heston\n",
    "        C_pred = self.pricer(S0, K, T, r, q, kappa, theta, sigma, rho, v0)\n",
    "\n",
    "        out = {\"kappa\": kappa, \"theta\": theta, \"sigma\": sigma, \"rho\": rho, \"v0\": v0, \"C_pred\": C_pred}\n",
    "        if C_mkt is None:\n",
    "            return out\n",
    "\n",
    "        # Perte ponderee par Vega + penalites\n",
    "        vega = bs_vega(S0, K, T, r, torch.zeros_like(r), iv)\n",
    "        mse_w = weighted_mse(C_pred, C_mkt, vega)\n",
    "        pen_feller = feller_penalty(kappa, theta, sigma).mean()\n",
    "        pen_ridge  = (kappa.mean() + theta.mean() + sigma.mean() + v0.mean() + rho.pow(2).mean())\n",
    "\n",
    "        loss = mse_w + lambda_feller*pen_feller + lambda_ridge*pen_ridge\n",
    "        out.update({\"loss\": loss, \"mse\": mse_w, \"pen_feller\": pen_feller, \"pen_ridge\": pen_ridge})\n",
    "        return out\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "2ab32ba3",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Fonctions de perte et penalites\n",
    "\n",
    "- **weighted_mse**: MSE ponderee par `1/(Vega+eps)`.  \n",
    "- **feller_penalty**: penalise les violations de `2*kappa*theta >= sigma^2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "32275668",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T21:48:23.170449Z",
     "start_time": "2025-11-11T21:48:23.167972Z"
    }
   },
   "source": [
    "\n",
    "def weighted_mse(C_pred: torch.Tensor, C_mkt: torch.Tensor, vega: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    \"\"\"MSE ponderee par 1/(Vega+eps) pour stabiliser l'apprentissage sur la surface.\"\"\"\n",
    "    w = 1.0 / (vega.abs() + eps)\n",
    "    diff = C_pred - C_mkt\n",
    "    return torch.mean((w * diff)**2)\n",
    "\n",
    "def feller_penalty(kappa: torch.Tensor, theta: torch.Tensor, sigma: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Penalite de violation de la condition de Feller: 2*kappa*theta >= sigma^2.\"\"\"\n",
    "    return torch.relu(sigma*sigma - 2.0*kappa*theta)\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "fdb4d8e7",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Boucle d'apprentissage minimale\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb325d6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T21:48:23.245547Z",
     "start_time": "2025-11-11T21:48:23.243050Z"
    }
   },
   "source": [
    "\n",
    "def train_step(model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "               batch_x: torch.Tensor, batch_Cmkt: torch.Tensor,\n",
    "               lambda_feller: float = 1e-3, lambda_ridge: float = 1e-6):\n",
    "    \"\"\"\n",
    "    Effectue une passe d'entrainement.\n",
    "    Retourne des statistiques utiles (loss, mse, feller).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(batch_x, C_mkt=batch_Cmkt, lambda_feller=lambda_feller, lambda_ridge=lambda_ridge)\n",
    "    out[\"loss\"].backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    return {k: (v.detach() if torch.is_tensor(v) else v) for k, v in out.items()}\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "af9b7dbc",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Donnees synthetiques et entrainement\n",
    "\n",
    "Ici, on cree une surface synthetique en prennant les **prix Black-Scholes** a volatilite implicite 20% comme proxy de **prix marche**.  \n",
    "En pratique, remplace par tes quotes.  \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd248e33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T21:54:23.830294Z",
     "start_time": "2025-11-11T21:54:23.752633Z"
    }
   },
   "source": [
    "# ======================\n",
    "# Chargement depuis ton CSV\n",
    "# ======================\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"D:/PycharmProjects/DAUPHINE/MyQuantGuild/Highlight/39. Heston Stochastic Volatility Model and Fast Fourier Transforms/NN/heston_training_surface.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "\n",
    "# Vérifie les colonnes attendues\n",
    "required_cols = {\"r\", \"T\", \"S0\", \"K\", \"iv_bs\", \"C_mkt\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Colonnes manquantes dans le CSV : {missing}\")\n",
    "\n",
    "# Nettoyage basique\n",
    "df = df.replace([float(\"inf\"), -float(\"inf\")], pd.NA).dropna(subset=list(required_cols))\n",
    "if df.empty:\n",
    "    raise ValueError(\"Le CSV ne contient aucune ligne valide après nettoyage.\")\n",
    "\n",
    "# Conversion en tenseurs torch\n",
    "r  = torch.tensor(df[\"r\"].values, dtype=torch.float64, device=device)\n",
    "T  = torch.tensor(df[\"T\"].values, dtype=torch.float64, device=device)\n",
    "S0 = torch.tensor(df[\"S0\"].values, dtype=torch.float64, device=device)\n",
    "K  = torch.tensor(df[\"K\"].values, dtype=torch.float64, device=device)\n",
    "iv = torch.tensor(df[\"iv_bs\"].values, dtype=torch.float64, device=device)\n",
    "C_mkt = torch.tensor(df[\"C_mkt\"].values, dtype=torch.float64, device=device)\n",
    "\n",
    "# Empilement des features : (r, T, S0, K, iv_bs)\n",
    "X = torch.stack([r, T, S0, K, iv], dim=1)\n",
    "\n",
    "# ======================\n",
    "# Initialisation modèle\n",
    "# ======================\n",
    "model = HestonCalibrator(hidden=128, N=2048, eta=0.20, alpha=1.5).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ======================\n",
    "# Entraînement\n",
    "# ======================\n",
    "EPOCHS = 15\n",
    "for epoch in range(EPOCHS):\n",
    "    stats = train_step(model, opt, X, C_mkt, lambda_feller=5e-4, lambda_ridge=1e-6)\n",
    "    print(f\"epoch {epoch+1:02d} | loss {stats['loss'].item():.6e} \"\n",
    "          f\"| mse {stats['mse'].item():.6e} | feller {stats['pen_feller'].item():.3e}\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/PycharmProjects/DAUPHINE/MyQuantGuild/Highlight/39. Heston Stochastic Volatility Model and Fast Fourier Transforms/NN/heston_training_surface.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m      6\u001B[39m csv_path = \u001B[33m\"\u001B[39m\u001B[33mD:/PycharmProjects/DAUPHINE/MyQuantGuild/Highlight/39. Heston Stochastic Volatility Model and Fast Fourier Transforms/NN/heston_training_surface.csv\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m df = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcsv_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# Vérifie les colonnes attendues\u001B[39;00m\n\u001B[32m     12\u001B[39m required_cols = {\u001B[33m\"\u001B[39m\u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mT\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mS0\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mK\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33miv_bs\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mC_mkt\u001B[39m\u001B[33m\"\u001B[39m}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda/envs/myQuantGuild/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda/envs/myQuantGuild/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda/envs/myQuantGuild/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda/envs/myQuantGuild/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda/envs/myQuantGuild/lib/python3.12/site-packages/pandas/io/common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'D:/PycharmProjects/DAUPHINE/MyQuantGuild/Highlight/39. Heston Stochastic Volatility Model and Fast Fourier Transforms/NN/heston_training_surface.csv'"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "bc1688a0",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Diagnostics rapides\n",
    "- Moyennes des parametres appris.  \n",
    "- Erreur de pricing vs K/S0.  \n",
    "- (Optionnel) verifie la parite put-call autour de l'ATM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    out = model(X)\n",
    "    for k in [\"kappa\",\"theta\",\"sigma\",\"rho\",\"v0\"]:\n",
    "        print(k, float(out[k].mean().item()))\n",
    "\n",
    "    C_pred = out[\"C_pred\"]\n",
    "    err = (C_pred - C_mkt).detach().cpu()\n",
    "    k_rel = (K/S0).detach().cpu()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(k_rel.numpy(), err.numpy(), marker='o', linestyle='None')\n",
    "plt.xlabel('K / S0')\n",
    "plt.ylabel('Erreur de prix (modele - marche)')\n",
    "plt.title('Erreur apres entrainement (demo synthetique)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb249df",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Utilisation avec donnees reelles\n",
    "\n",
    "Attendu: un DataFrame avec colonnes `['r','T','S0','K','iv_bs','C_mkt']`. Exemple minimal:\n",
    "\n",
    "```python\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('vos_quotes.csv')\n",
    "\n",
    "r  = torch.tensor(df['r'    ].values, dtype=torch.float64, device=device)\n",
    "T  = torch.tensor(df['T'    ].values, dtype=torch.float64, device=device)\n",
    "S0 = torch.tensor(df['S0'   ].values, dtype=torch.float64, device=device)\n",
    "K  = torch.tensor(df['K'    ].values, dtype=torch.float64, device=device)\n",
    "iv = torch.tensor(df['iv_bs'].values, dtype=torch.float64, device=device)\n",
    "C_mkt = torch.tensor(df['C_mkt'].values, dtype=torch.float64, device=device)\n",
    "\n",
    "X = torch.stack([r,T,S0,K,iv], dim=1)\n",
    "\n",
    "# Puis reutiliser train_step avec mini-batches si dataset volumineux.\n",
    "```\n",
    "\n",
    "### Conseils pratiques\n",
    "- Commencer avec `N=1024..2048`, `eta ~ 0.15..0.30`, `alpha ~ 1.3..1.7`.\n",
    "- Conserver `float64` pour la couche de pricing.\n",
    "- Normaliser les features (log des prix, mise a l'echelle de T) si besoin.\n",
    "- Sur oscilliations: reduire `lr`, augmenter `alpha` ou `N`, ou renforcer la penalite Feller.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
